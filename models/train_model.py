# ì¸µê°„ì†ŒìŒ ì¢…ë¥˜ë¥¼ ë¶„ë¥˜í•˜ëŠ” AI ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate
from tensorflow.keras.models import Model
import joblib

# 1. ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    df = pd.read_csv("real_noise_data.csv")
except FileNotFoundError:
    print("âŒ 'real_noise_data.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ë¨¼ì € 'labels.csv' íŒŒì¼ì„ ì‘ì„±í•œ í›„, 'build_dataset.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
    exit()

# ë¬¸ìì—´ë¡œ ëœ ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‹¤ì œ ìˆ˜ì¹˜ ë°ì´í„°ë¡œ ë³€í™˜
def str_to_list(s):
    import json
    return np.array(json.loads(s))

print(f"ì´ {len(df)}ê°œì˜ ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œë¡œ í•™ìŠµì„ ì¤€ë¹„í•©ë‹ˆë‹¤...")

X_vibration = np.stack(df['vibration_sample'].apply(str_to_list))
# Pad/truncate vibration data to a fixed length, e.g., 50
fixed_vib_length = 50
X_vibration_padded = np.array([np.pad(v, (0, fixed_vib_length - len(v)), 'constant') if len(v) < fixed_vib_length else v[:fixed_vib_length] for v in X_vibration])

X_sound_mfcc = np.stack(df['sound_sample'].apply(str_to_list))
y = df['label']

# 2. ì „ì²˜ë¦¬ (ì •ë‹µ ë¼ë²¨ ìˆ˜ì¹˜í™”)
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# CNN ì…ë ¥ì„ ìœ„í•´ MFCC ë°ì´í„°ë¥¼ 2D ì´ë¯¸ì§€ í˜•íƒœë¡œ Reshape
n_mfcc = X_sound_mfcc.shape[1]
n_frames = X_sound_mfcc.shape[2]
X_sound_reshaped = X_sound_mfcc.reshape(-1, n_mfcc, n_frames, 1)

# ì§„ë™ ë°ì´í„°ëŠ” StandardScalerë¡œ ì •ê·œí™”
scaler = StandardScaler()
X_vibration_scaled = scaler.fit_transform(X_vibration_padded)


X_train_sound, X_test_sound, X_train_vibration, X_test_vibration, y_train, y_test = train_test_split(
    X_sound_reshaped, X_vibration_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

# 3. ëª¨ë¸ ì„¤ê³„ (CNNê³¼ DNNì„ ê²°í•©í•œ ë©€í‹°ëª¨ë‹¬ êµ¬ì¡°)

# --- CNN ë¶„ê¸° (ì†Œë¦¬ íŠ¹ì§• ì²˜ë¦¬) ---
sound_input = Input(shape=(n_mfcc, n_frames, 1), name='sound_input')
x = Conv2D(32, (3, 3), activation='relu', padding='same')(sound_input)
x = MaxPooling2D((2, 2))(x)
x = Dropout(0.25)(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)
x = Dropout(0.25)(x)
x = Flatten()(x)
sound_output = Dense(32, activation='relu')(x)

# --- DNN ë¶„ê¸° (ì§„ë™ íŠ¹ì§• ì²˜ë¦¬) ---
vibration_input = Input(shape=(X_vibration_scaled.shape[1],), name='vibration_input')
y = Dense(16, activation='relu')(vibration_input)
vibration_output = Dense(8, activation='relu')(y)

# --- íŠ¹ì§• ê²°í•© ë° ìµœì¢… ë¶„ë¥˜ ---
combined = Concatenate()([sound_output, vibration_output])
z = Dense(64, activation='relu')(combined)
z = Dropout(0.5)(z)
output = Dense(len(le.classes_), activation='softmax', name='output')(z)

model = Model(inputs=[sound_input, vibration_input], outputs=output)

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

# 4. í•™ìŠµ ì‹œì‘
print("\nğŸš€ ìƒˆë¡œìš´ CNN ê¸°ë°˜ AI ëª¨ë¸ ì¬í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
history = model.fit(
    [X_train_sound, X_train_vibration], 
    y_train, 
    epochs=30, 
    batch_size=16, 
    validation_data=([X_test_sound, X_test_vibration], y_test),
    verbose=2
)

# 5. ëª¨ë¸ ë° Scaler ì €ì¥
model.save("noise_model_v2.h5")
np.save("classes_v2.npy", le.classes_)
joblib.dump(scaler, 'vibration_scaler_v2.joblib') # Save the fitted scaler

print("\nâœ… ì¬í•™ìŠµ ì™„ë£Œ! 'noise_model_v2.h5', 'classes_v2.npy', 'vibration_scaler_v2.joblib' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("ìƒˆë¡œìš´ ëª¨ë¸ì„ ì ìš©í•˜ë ¤ë©´, ai_model.pyì˜ load_ai_model í•¨ìˆ˜ì—ì„œ ê´€ë ¨ íŒŒì¼ëª…ì„ v2ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”.")